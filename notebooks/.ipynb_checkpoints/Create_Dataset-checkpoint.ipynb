{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a00bedb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:48:02|TQ-INFO| Initializing torchquad.\n",
      "13:48:03|TQ-INFO| __pyTorch VERSION:<module 'torch.version' from '/home/math/maskey/anaconda3/envs/pyg_cuda102/lib/python3.8/site-packages/torch/version.py'>\n",
      "13:48:03|TQ-INFO| __CUDNN VERSION:7605\n",
      "13:48:03|TQ-INFO| __Number of CUDA Devices:2\n",
      "13:48:04|TQ-INFO| Active CUDA Device: GPU0\n",
      "13:48:04|TQ-INFO| Setting default tensor type to cuda.Float32 (CUDA is initialized).\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import pickle #for saving and loading the dataset\n",
    "import _pickle as cPickle\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import time\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "import random\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "# For plotting\n",
    "\n",
    "# To avoid copying things to GPU memory,\n",
    "# ideally allocate everything in torch on the GPU\n",
    "# and avoid non-torch function calls\n",
    "torch.set_printoptions(precision=10) # Set displayed output precision to 10 digits\n",
    "\n",
    "from torchquad import enable_cuda # Necessary to enable GPU support\n",
    "from torchquad import Trapezoid, Simpson, Boole, MonteCarlo, VEGAS # The available integrators\n",
    "import torchquad\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "enable_cuda() # Use this to enable GPU support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "815c7c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dafea253",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10002 #How large shall the graphs become?\n",
    "skip = 100 #Should we consider all graphs, or only every skip'th\n",
    "r = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b31099fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetList2 = []\n",
    "positions2 = []\n",
    "graphSignals2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56d89dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.02091383934020996\n",
      "101 0.024313926696777344\n",
      "201 0.02780938148498535\n",
      "301 0.030412912368774414\n",
      "401 0.02399730682373047\n",
      "501 0.026182174682617188\n",
      "601 0.06059432029724121\n",
      "701 0.03540849685668945\n",
      "801 0.06813478469848633\n",
      "901 0.06551933288574219\n",
      "1001 0.06038236618041992\n",
      "1101 0.03251361846923828\n",
      "1201 0.028159141540527344\n",
      "1301 0.03324556350708008\n",
      "1401 0.036527156829833984\n",
      "1501 0.030572175979614258\n",
      "1601 0.03925323486328125\n",
      "1701 0.05272412300109863\n",
      "1801 0.05891227722167969\n",
      "1901 0.06542062759399414\n",
      "2001 0.050073862075805664\n",
      "2101 0.04785728454589844\n",
      "2201 0.20903277397155762\n",
      "2301 0.10535264015197754\n",
      "2401 0.18141722679138184\n",
      "2501 0.18848061561584473\n",
      "2601 0.22216057777404785\n",
      "2701 0.23938965797424316\n",
      "2801 0.18524599075317383\n",
      "2901 0.199143648147583\n",
      "3001 0.24930167198181152\n",
      "3101 0.2171497344970703\n",
      "3201 0.3086273670196533\n",
      "3301 0.39133572578430176\n",
      "3401 0.3579373359680176\n",
      "3501 0.4278395175933838\n",
      "3601 0.4525742530822754\n",
      "3701 0.42477989196777344\n",
      "3801 0.42534828186035156\n",
      "3901 0.41563844680786133\n",
      "4001 0.45316243171691895\n",
      "4101 0.5274708271026611\n",
      "4201 0.6274282932281494\n",
      "4301 0.9896836280822754\n",
      "4401 0.9050278663635254\n",
      "4501 2.083275318145752\n",
      "4601 0.8435943126678467\n",
      "4701 0.7833380699157715\n",
      "4801 0.8929054737091064\n",
      "4901 0.7998945713043213\n",
      "5001 1.1181201934814453\n",
      "5101 1.052461862564087\n",
      "5201 1.1291701793670654\n",
      "5301 1.1582608222961426\n",
      "5401 1.0636804103851318\n",
      "5501 1.1301579475402832\n",
      "5601 1.070725679397583\n",
      "5701 1.1436553001403809\n",
      "5801 1.236522912979126\n",
      "5901 1.3911683559417725\n",
      "6001 1.3559277057647705\n",
      "6101 1.3401870727539062\n",
      "6201 1.6260573863983154\n",
      "6301 1.3506145477294922\n",
      "6401 1.2086944580078125\n",
      "6501 1.4421947002410889\n",
      "6601 1.405428409576416\n",
      "6701 1.407721996307373\n",
      "6801 1.1789906024932861\n",
      "6901 1.2465524673461914\n",
      "7001 1.5363223552703857\n",
      "7101 1.6381664276123047\n",
      "7201 1.5363683700561523\n",
      "7301 1.7328307628631592\n",
      "7401 1.6660716533660889\n",
      "7501 2.003732204437256\n",
      "7601 1.722937822341919\n",
      "7701 0.7860345840454102\n",
      "7801 1.0210177898406982\n",
      "7901 0.8619005680084229\n",
      "8001 0.9134831428527832\n",
      "8101 1.0043647289276123\n",
      "8201 1.0888240337371826\n",
      "8301 1.111872911453247\n",
      "8401 1.0410277843475342\n",
      "8501 1.0919501781463623\n",
      "8601 1.068302869796753\n",
      "8701 1.5285930633544922\n",
      "8801 1.8378379344940186\n",
      "8901 1.8093750476837158\n",
      "9001 1.6247053146362305\n",
      "9101 1.9013001918792725\n",
      "9201 1.786724328994751\n",
      "9301 1.8220491409301758\n",
      "9401 2.087495803833008\n",
      "9501 2.007131576538086\n",
      "9601 1.6647160053253174\n",
      "9701 1.5707588195800781\n",
      "9801 1.6963722705841064\n",
      "9901 2.0964627265930176\n",
      "10001 1.6982293128967285\n"
     ]
    }
   ],
   "source": [
    "for j in range(1,N,skip):\n",
    "    start = time.time()\n",
    "\n",
    "    with open('../input/OldData/RGG_add_' + str(j) +'.pickle', 'rb') as data:\n",
    "        graph = pickle.load(data)\n",
    "    with open('../input/OldData/graph_signal_add_' + str(j) +'.pickle', 'rb') as data:\n",
    "        graph_signal = pickle.load(data)  \n",
    "    with open('../input/OldData/pos_add_' + str(j) +'.pickle', 'rb') as data:\n",
    "        pos = pickle.load(data)\n",
    "    positions2.append(pos)\n",
    "    datasetList2.append(graph)\n",
    "    graphSignals2.append(graph_signal)\n",
    "    \n",
    "    end = time.time()\n",
    "    print(j, end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97bad451",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input/graphDataset_' + str(N) + 'Nodes'+ '.pickle', 'wb') as output:\n",
    "    pickle.dump(datasetList2, output)\n",
    "with open('../input/graphSignalDataset_' + str(N) + 'Nodes'+ '.pickle', 'wb') as output:\n",
    "    pickle.dump(graphSignals2, output)\n",
    "with open('../input/positionsDataset_' + str(N) + 'Nodes'+ '.pickle', 'wb') as output:\n",
    "    pickle.dump(positions2, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2b85a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
