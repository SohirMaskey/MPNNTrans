{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07848051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Dataset, download_url\n",
    "\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import pickle #for saving and loading the dataset\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import time\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "import random\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0ce50d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGGDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, root, fct = lambda x: x[0]*x[1] , transform=None, pre_transform=None, size=1002, skip=100):\n",
    "        \"\"\"\n",
    "        root = where the dataset should be stored. \n",
    "        This folder is split into raw_dir (downloaded dataset) and processed_dir (processed data)\n",
    "\n",
    "        \"\"\"\n",
    "        #super(RGGDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.fct = fct #this is the function that we use for sampling things\n",
    "        self.size = size\n",
    "        self.skip = skip\n",
    "        self.root = root\n",
    "    \n",
    "    size = 1002\n",
    "    skip = 100\n",
    "    \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        \"\"\" If this file exists in raw_dir, the download is not triggered.\n",
    "            (The download func. is not implemented here)  \n",
    "        \"\"\"\n",
    "        return [f'RGG_{i}.pickle' for i in range(1, self.size, self.skip)]\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        \"\"\" If these files are found in processed_dir, processing is skipped\"\"\"\n",
    "        \n",
    "        return [f'data_{i}.pt' for i in range(1, self.size, self.skip)]\n",
    "    \n",
    "    def download(self):\n",
    "        #we dont really download anything graph_signal_10001.pickle\n",
    "        pass\n",
    "\n",
    "    def process(self):    \n",
    "        for i in range(1, self.size, self.skip): #need to give the length somehow\n",
    "            with open(f'../input/raw/RGG_{i}.pickle', 'rb') as data:\n",
    "                graph = pickle.load(data)\n",
    "            \n",
    "            try:\n",
    "                with open(f'../input/raw/graph_signal_{i}.pickle', 'rb') as data:\n",
    "                    graph_signal = pickle.load(data)\n",
    "            except:\n",
    "                graph_signal = torch.ones(i)\n",
    "            \n",
    "            #with open(f'../input/graph_signal_{i}.pickle', 'rb') as data:\n",
    "            #    graph_signal = pickle.load(data)\n",
    "                \n",
    "            #with open(f'../input/pos_{i}.pickle', 'rb') as data:\n",
    "            #    self.pos = pickle.load(data)\n",
    "            # Create data object\n",
    "            graph.x = torch.tensor(graph_signal)\n",
    "            #data.pos = self.pos #Every graph data object gets a position attribute\n",
    "            torch.save(graph, \n",
    "                os.path.join(self.processed_dir, \n",
    "                    f'data_{i}.pt'))\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.size)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(osp.join(self.processed_dir, 'data_{}.pt'.format(idx)))\n",
    "        return data\n",
    "    \n",
    "    \"\"\"\n",
    "    I do not write a function to get and set node features and edge features because the Data objects \n",
    "    already have it, so that one can iterate through the data object then.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc4a5c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    RGG10002 = RGGDataset(root = \"../input\", size = 10002\n",
    "                         )\n",
    "    RGG10002.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf3ad3f",
   "metadata": {},
   "source": [
    "#the old class\n",
    "\n",
    "class RGGDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        \"\"\"\n",
    "        root = where the dataset should be stored. \n",
    "        This folder is split into raw_dir (downloaded dataset) and processed_dir (processed data)\n",
    "\n",
    "        \"\"\"\n",
    "        super(RGGDataset, self).__init__(root, transform, pre_transform)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        \"\"\" If this file exists in raw_dir, the download is not triggered.\n",
    "            (The download func. is not implemented here)  \n",
    "        \"\"\"\n",
    "        return ['graphDataset_502Nodes.pickle', 'graphSignalDataset_502Nodes.pickle', 'positionsDataset_502Nodes.pickle']\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        \"\"\" If these files are found in processed_dir, processing is skipped\"\"\"\n",
    "        \n",
    "        return [f'data_{i}.pt' for i in range(1,101)]\n",
    "    \n",
    "    def download(self):\n",
    "        #we dont really download anything\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        with open('../input/graphDataset_10002Nodes.pickle', 'rb') as data:\n",
    "            self.graphs = pickle.load(data)\n",
    "        with open('../input/graphSignalDataset_10002Nodes.pickle', 'rb') as data:\n",
    "            self.graph_signals = pickle.load(data)  \n",
    "        with open('../input/positionsDataset_10002Nodes.pickle', 'rb') as data:\n",
    "            self.pos = pickle.load(data)\n",
    "        for i in range(1, len(self.graphs)):\n",
    "        # Create data object\n",
    "            data = Data(x=self.graph_signals[i], \n",
    "                        edge_index=self.graphs[i].edge_index,\n",
    "                        ) \n",
    "            torch.save(data, \n",
    "                os.path.join(self.processed_dir, \n",
    "                    f'data_{i}.pt'))\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(osp.join(self.processed_dir, 'data_{}.pt'.format(idx)))\n",
    "        return data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
